DataParams

TrainParams

batch_size = 32
accumulate_grad_batches = 1
epochs = 2
lr = 1e-3
max_sample_tokens = 200
lr_warm_steps = 100
lr_cycle_steps=500



ModelParams

n_layers = 3
n_heads = 4
dim = 256
max_seq_len = 200
tokenizer_source_name = "char" 